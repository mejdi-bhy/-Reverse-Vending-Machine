{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **This lab aims to collect data for the feature-based volume classification model. Features including the width of the bounding box, the height of the bounding box, the type of the recyclable object, whether smashed or not, etc...**","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport keras\nimport numpy as np\nimport tensorflow as tf\nfrom keras.utils import normalize\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the dataset that will be used to collect the data for the volume classification model\n!gdown https://drive.google.com/uc?id=1FpJBz9gSO0xLCwBoZ5rQUvq-jSoGjBrx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unzipping the dataset compressed file\n!unzip dataset_for_volume_classification_model.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the  compressed dataset file(no need for the compressed files)\n!rm dataset_for_volume_classification_model.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_directory = \"dataset_for_volume_classification_model\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#These are all the classes(categories) we want our volume classification model to classify later on\nos.listdir(dataset_directory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Extracting the width of the bounding box, the height of the bounding box, the surface of the bounding box and the type of the recyclable object(bottle, can)**","metadata":{}},{"cell_type":"code","source":"# Importing the object detection model (tflite version)\n!gdown https://drive.google.com/uc?id=1--pJA_MACxCL04uw7u_zqmJCSIi7faYp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unzipping the object detection model compressed file\n!unzip object_detection_model_tflite.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the compressed object detection model file(no need for the compressed files)\n!rm object_detection_model_tflite.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!touch object_detection_model_tflite/labels.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('object_detection_model_tflite/labels.txt', 'w') as f:\n    f.write(\"bottle\\n\")\n    f.write(\"cup\\n\")\n    f.write(\"nocup\\n\")\n    f.write(\"can\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tflite-runtime","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tflite_runtime.interpreter import Interpreter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_labels(path='object_detection_model_tflite/labels.txt'):\n  \"\"\"Loads the labels file. Supports files with or without index numbers.\"\"\"\n  with open(path, 'r', encoding='utf-8') as f:\n    lines = f.readlines()\n    labels = {}\n    for row_number, content in enumerate(lines):\n      pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\n      if len(pair) == 2 and pair[0].strip().isdigit():\n        labels[int(pair[0])] = pair[1].strip()\n      else:\n        labels[row_number] = pair[0].strip()\n  return labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_input_tensor(interpreter, image):\n  \"\"\"Sets the input tensor.\"\"\"\n  tensor_index = interpreter.get_input_details()[0]['index']\n  input_tensor = interpreter.tensor(tensor_index)()[0]\n  input_tensor[:, :] = np.expand_dims(image, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_output_tensor(interpreter, index):\n  \"\"\"Returns the output tensor at the given index.\"\"\"\n  output_details = interpreter.get_output_details()[int(index)]\n  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\n  return tensor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_objects(interpreter, image, threshold):\n  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n  set_input_tensor(interpreter, image)\n  interpreter.invoke()\n  # Get all output details\n  boxes = get_output_tensor(interpreter, 1)\n  classes = get_output_tensor(interpreter, 3)\n  scores = get_output_tensor(interpreter, 0)\n  count = int(get_output_tensor(interpreter, 2))\n  results = []\n  for i in range(count):\n    if scores[i] >= threshold:\n      result = {\n          'bounding_box': boxes[i],\n          'class_id': classes[i],\n          'score': scores[i]\n      }\n      results.append(result)\n  return results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = load_labels()\ninterpreter = Interpreter('object_detection_model_tflite/saved_model/object_detection_model.tflite')\ninterpreter.allocate_tensors()\n_, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def object_detection(img_path):\n    img = cv2.imread(img_path)\n    img = np.array(img)\n    img = cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), (512,512))\n    results = detect_objects(interpreter, img, 0.4)\n    return results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['bottle', 'cup', 'nocup', 'can']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(columns=[\"ymin\", \"xmin\", \"ymax\", \"xmax\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detected_objects = []\ndetected_boxes = []\nfor directory in os.listdir(dataset_directory):\n    for i, img in enumerate(os.listdir(os.path.join(dataset_directory, directory))):\n        img_path = os.path.join(dataset_directory, directory, img)\n        results = object_detection(img_path)\n        for result in results:\n            detected_objects.append(labels[int(result['class_id'])])\n            detected_boxes.append(result['bounding_box'])\n            \nfor detected_box in detected_boxes:\n    df = pd.DataFrame([detected_box], columns=[\"ymin\", \"xmin\", \"ymax\", \"xmax\"])\n    data = pd.concat([data, df], axis=0, ignore_index=True)\n   \ndata = data.assign(detected_object=pd.Series(detected_objects).values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[((data[\"detected_object\"] == \"bottle\") | (data[\"detected_object\"] == \"can\"))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\nwidth = data['xmax'] - data['xmin']\ndf = df.assign(width=pd.Series(width).values)\nheight = data['ymax'] - data['ymin']\ndf = df.assign(height=pd.Series(height).values)\nsurface = width*height\ndf = df.assign(surface=pd.Series(surface).values)\ndetected_object = data['detected_object']\ndf = df.assign(detected_object=pd.Series(detected_object).values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Extracting whether or not the recyclable object is defective (smashed)**","metadata":{}},{"cell_type":"code","source":"# Importing the defective_non_defective classification model(tflite version)\n!gdown https://drive.google.com/uc?id=1-0WB4vJoYlaD8ise2n9LO65JCSsTHQxX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unzipping the defective_non_defective classification model compressed file\n!unzip defective_non_defective_classification_model_tflite.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing the defective_non_defective classification model compressed file(no need for the compressed files)\n!rm defective_non_defective_classification_model_tflite.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(model_path=\"defective_non_defective_classification_model_tflite.tflite\")\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Test the model on random input data.\ninput_shape = input_details[0]['shape']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['non_defective', 'defective']","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:25:03.971729Z","iopub.execute_input":"2023-04-30T00:25:03.973005Z","iopub.status.idle":"2023-04-30T00:25:03.978406Z","shell.execute_reply.started":"2023-04-30T00:25:03.972954Z","shell.execute_reply":"2023-04-30T00:25:03.977193Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"def defective_non_defective(img_path):\n    img = cv2.imread(img_path)\n    img = cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), (512,512))\n    img = np.array(img)\n    img = img/255.0\n    img = img.astype(np.float32)\n    img = np.expand_dims(img, axis=0)\n    interpreter.set_tensor(input_details[0]['index'], img)\n    interpreter.invoke()\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    predicted_class = np.argmax(output_data)\n    return classes[predicted_class]","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:25:06.146654Z","iopub.execute_input":"2023-04-30T00:25:06.147606Z","iopub.status.idle":"2023-04-30T00:25:06.158967Z","shell.execute_reply.started":"2023-04-30T00:25:06.147553Z","shell.execute_reply":"2023-04-30T00:25:06.158066Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"results = []\nfor directory in os.listdir(dataset_directory):\n    for i, img in enumerate(os.listdir(os.path.join(dataset_directory, directory))):\n        img_path = os.path.join(dataset_directory, directory, img)\n        predict = defective_non_defective(img_path)\n        results.append(predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.assign(object_condition=pd.Series(results).values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"volume = []\nfor directory in os.listdir(dataset_directory):\n    for i, img in enumerate(os.listdir(os.path.join(dataset_directory, directory))):\n        volume.append(directory)\nvolume = [float(v) for v in volume]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_v1 = df.copy()","metadata":{"execution":{"iopub.status.busy":"2023-04-29T23:54:09.769548Z","iopub.execute_input":"2023-04-29T23:54:09.770474Z","iopub.status.idle":"2023-04-29T23:54:09.775830Z","shell.execute_reply.started":"2023-04-29T23:54:09.770434Z","shell.execute_reply":"2023-04-29T23:54:09.774673Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"df_v1 = df_v1.assign(volume=pd.Series(volume).values)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T23:54:45.705936Z","iopub.execute_input":"2023-04-29T23:54:45.706384Z","iopub.status.idle":"2023-04-29T23:54:45.714608Z","shell.execute_reply.started":"2023-04-29T23:54:45.706321Z","shell.execute_reply":"2023-04-29T23:54:45.713539Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"df_v1.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-29T23:54:58.116429Z","iopub.execute_input":"2023-04-29T23:54:58.116795Z","iopub.status.idle":"2023-04-29T23:54:58.130871Z","shell.execute_reply.started":"2023-04-29T23:54:58.116765Z","shell.execute_reply":"2023-04-29T23:54:58.129567Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"      width    height   surface detected_object object_condition  volume\n0  0.405624  0.271085  0.109959          bottle        defective     0.5\n1  0.395052  0.267947  0.105853          bottle        defective     0.5\n2  0.440588  0.209557  0.092328          bottle    non_defective     0.5\n3  0.450576  0.264297  0.119086          bottle        defective     0.5\n4  0.419848  0.212147  0.089069          bottle    non_defective     0.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>width</th>\n      <th>height</th>\n      <th>surface</th>\n      <th>detected_object</th>\n      <th>object_condition</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.405624</td>\n      <td>0.271085</td>\n      <td>0.109959</td>\n      <td>bottle</td>\n      <td>defective</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.395052</td>\n      <td>0.267947</td>\n      <td>0.105853</td>\n      <td>bottle</td>\n      <td>defective</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.440588</td>\n      <td>0.209557</td>\n      <td>0.092328</td>\n      <td>bottle</td>\n      <td>non_defective</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.450576</td>\n      <td>0.264297</td>\n      <td>0.119086</td>\n      <td>bottle</td>\n      <td>defective</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.419848</td>\n      <td>0.212147</td>\n      <td>0.089069</td>\n      <td>bottle</td>\n      <td>non_defective</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_v1.to_csv('dataset_for_volume_classification_model_v1.csv', encoding='utf-8', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:00:23.512172Z","iopub.execute_input":"2023-04-30T00:00:23.512894Z","iopub.status.idle":"2023-04-30T00:00:23.522966Z","shell.execute_reply.started":"2023-04-30T00:00:23.512856Z","shell.execute_reply":"2023-04-30T00:00:23.521850Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":" ## **Extracting the brand of the recyclable object**","metadata":{}},{"cell_type":"code","source":"# Importing the brand classification model(tflite version)\n!gdown https://drive.google.com/uc?id=1bv48M1nLuxlCMZp5Qm1ZtqYAnLTU0K1t","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:51:04.797194Z","iopub.execute_input":"2023-04-30T00:51:04.797892Z","iopub.status.idle":"2023-04-30T00:51:20.565243Z","shell.execute_reply.started":"2023-04-30T00:51:04.797852Z","shell.execute_reply":"2023-04-30T00:51:20.564060Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=1bv48M1nLuxlCMZp5Qm1ZtqYAnLTU0K1t\nFrom (redirected): https://drive.google.com/uc?id=1bv48M1nLuxlCMZp5Qm1ZtqYAnLTU0K1t&confirm=t&uuid=62f082f5-b689-49a8-a1ab-9644646ff736\nTo: /kaggle/working/brand_classification_model_tflite.zip\n100%|████████████████████████████████████████| 688M/688M [00:12<00:00, 55.3MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Unzipping the brand classification model compressed file\n!unzip brand_classification_model_tflite.zip","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:52:11.940923Z","iopub.execute_input":"2023-04-30T00:52:11.941920Z","iopub.status.idle":"2023-04-30T00:52:20.222150Z","shell.execute_reply.started":"2023-04-30T00:52:11.941871Z","shell.execute_reply":"2023-04-30T00:52:20.220977Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"Archive:  brand_classification_model_tflite.zip\n  inflating: volume_brand_classification_model_tflite.tflite  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Remove the brand classification model compressed file(no need for the compressed files)\n!rm brand_classification_model_tflite.zip","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:52:32.485020Z","iopub.execute_input":"2023-04-30T00:52:32.485429Z","iopub.status.idle":"2023-04-30T00:52:33.584691Z","shell.execute_reply.started":"2023-04-30T00:52:32.485387Z","shell.execute_reply":"2023-04-30T00:52:33.583292Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(model_path=\"volume_brand_classification_model_tflite.tflite\")\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Test the model on random input data.\ninput_shape = input_details[0]['shape']","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:53:31.384751Z","iopub.execute_input":"2023-04-30T00:53:31.385581Z","iopub.status.idle":"2023-04-30T00:53:32.307888Z","shell.execute_reply.started":"2023-04-30T00:53:31.385536Z","shell.execute_reply":"2023-04-30T00:53:32.306417Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"classes = [\n    'BOTTLE_0,5_SAFIA',\n     'BOTTLE_0,5_ROYALE',\n     'BOTTLE_1,0_MIRA',\n     'BOTTLE_1,5_MELLITI',\n     'CAN_0,24_SPRITE',\n     'BOTTLE_0,5_CRISTALINE',\n     'BOTTLE_1,5_DELICE',\n     'BOTTLE_1,5_BOGACIDRE',\n     'BOTTLE_0,5_MARWA',\n     'CAN_0,24_BOGACITRON',\n     'BOTTLE_2,0_DIMA',\n     'BOTTLE_1,5_SAFIA',\n     'BOTTLE_1,5_MARWA',\n     'BOTTLE_0,5_TIBA',\n     'CAN_0,24_COCA',\n     'BOTTLE_2,0_DENYA',\n     'CAN_0,24_FANTA',\n     'BOTTLE_1,5_TIJEN',\n     'CAN_0,24_ORANGINA',\n     'BOTTLE_0,5_TIJEN',\n     'BOTTLE_0,5_COCA',\n     'BOTTLE_0,5_BEYA',\n     'BOTTLE_2,0_FOURAT',\n     'BOTTLE_0,5_DELICE',\n     'BOTTLE_0,5_AQUALINE',\n     'CAN_0,24_APLA',\n     'BOTTLE_1,5_SABRINE',\n     'BOTTLE_1,5_BARGOU',\n     'BOTTLE_0,5_MIRA',\n     'BOTTLE_1,5_COCA',\n     'BOTTLE_0,5_DIMA',\n     'CAN_0,24_BOGACIDRE']","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:54:47.510603Z","iopub.execute_input":"2023-04-30T00:54:47.511350Z","iopub.status.idle":"2023-04-30T00:54:47.517198Z","shell.execute_reply.started":"2023-04-30T00:54:47.511294Z","shell.execute_reply":"2023-04-30T00:54:47.516180Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"def brand_classification(img_path):\n    img = cv2.imread(img_path)\n    img = cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), (512,512))\n    img = np.array(img)\n    img = img/255.0\n    img = img.astype(np.float32)\n    img = np.expand_dims(img, axis=0)\n    interpreter.set_tensor(input_details[0]['index'], img)\n    interpreter.invoke()\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    predicted_class = np.argmax(output_data)\n    return classes[predicted_class]","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:55:44.634308Z","iopub.execute_input":"2023-04-30T00:55:44.635504Z","iopub.status.idle":"2023-04-30T00:55:44.642971Z","shell.execute_reply.started":"2023-04-30T00:55:44.635449Z","shell.execute_reply":"2023-04-30T00:55:44.641747Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"brands = []\nfor directory in os.listdir(dataset_directory):\n    for i, img in enumerate(os.listdir(os.path.join(dataset_directory, directory))):\n        img_path = os.path.join(dataset_directory, directory, img)\n        brand = brand_classification(img_path)\n        brands.append(brand)\nbrands = [brand.split('_')[2] for brand in brands]","metadata":{"execution":{"iopub.status.busy":"2023-04-30T00:59:42.342415Z","iopub.execute_input":"2023-04-30T00:59:42.343136Z","iopub.status.idle":"2023-04-30T01:03:08.256495Z","shell.execute_reply.started":"2023-04-30T00:59:42.343098Z","shell.execute_reply":"2023-04-30T01:03:08.255263Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"df_v2 = df.copy()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T01:06:29.042268Z","iopub.execute_input":"2023-04-30T01:06:29.043276Z","iopub.status.idle":"2023-04-30T01:06:29.049359Z","shell.execute_reply.started":"2023-04-30T01:06:29.043236Z","shell.execute_reply":"2023-04-30T01:06:29.048223Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"df_v2 = df_v2.assign(brand=pd.Series(brands).values)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T01:06:32.970840Z","iopub.execute_input":"2023-04-30T01:06:32.972184Z","iopub.status.idle":"2023-04-30T01:06:32.978846Z","shell.execute_reply.started":"2023-04-30T01:06:32.972135Z","shell.execute_reply":"2023-04-30T01:06:32.977458Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"df_v2 = df_v2.assign(volume=pd.Series(volume).values)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T01:06:35.704938Z","iopub.execute_input":"2023-04-30T01:06:35.706010Z","iopub.status.idle":"2023-04-30T01:06:35.713056Z","shell.execute_reply.started":"2023-04-30T01:06:35.705957Z","shell.execute_reply":"2023-04-30T01:06:35.712034Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"df_v2.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T01:06:41.917445Z","iopub.execute_input":"2023-04-30T01:06:41.918145Z","iopub.status.idle":"2023-04-30T01:06:41.932703Z","shell.execute_reply.started":"2023-04-30T01:06:41.918108Z","shell.execute_reply":"2023-04-30T01:06:41.931392Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"      width    height   surface detected_object object_condition  brand  \\\n0  0.405624  0.271085  0.109959          bottle        defective   DIMA   \n1  0.395052  0.267947  0.105853          bottle        defective  TIJEN   \n2  0.440588  0.209557  0.092328          bottle    non_defective   COCA   \n3  0.450576  0.264297  0.119086          bottle        defective   MIRA   \n4  0.419848  0.212147  0.089069          bottle    non_defective  TIJEN   \n\n   volume  \n0     0.5  \n1     0.5  \n2     0.5  \n3     0.5  \n4     0.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>width</th>\n      <th>height</th>\n      <th>surface</th>\n      <th>detected_object</th>\n      <th>object_condition</th>\n      <th>brand</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.405624</td>\n      <td>0.271085</td>\n      <td>0.109959</td>\n      <td>bottle</td>\n      <td>defective</td>\n      <td>DIMA</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.395052</td>\n      <td>0.267947</td>\n      <td>0.105853</td>\n      <td>bottle</td>\n      <td>defective</td>\n      <td>TIJEN</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.440588</td>\n      <td>0.209557</td>\n      <td>0.092328</td>\n      <td>bottle</td>\n      <td>non_defective</td>\n      <td>COCA</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.450576</td>\n      <td>0.264297</td>\n      <td>0.119086</td>\n      <td>bottle</td>\n      <td>defective</td>\n      <td>MIRA</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.419848</td>\n      <td>0.212147</td>\n      <td>0.089069</td>\n      <td>bottle</td>\n      <td>non_defective</td>\n      <td>TIJEN</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_v2.to_csv('dataset_for_volume_classification_model_v2.csv', encoding='utf-8', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T01:06:59.474364Z","iopub.execute_input":"2023-04-30T01:06:59.475043Z","iopub.status.idle":"2023-04-30T01:06:59.486031Z","shell.execute_reply.started":"2023-04-30T01:06:59.475005Z","shell.execute_reply":"2023-04-30T01:06:59.484988Z"},"trusted":true},"execution_count":133,"outputs":[]}]}